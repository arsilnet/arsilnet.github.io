<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Resume - Start Bootstrap Theme</title>
        <link rel="icon" type="image/x-icon" href="assets/img/logo.png" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.4/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
        <link rel="stylesheet" href="assets/css/academicons.min.css"/>
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Clarence Taylor</span>
                <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/img/profile.png" alt="..." /></span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#experience">Experience</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#skills">Projects</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#interests">Skills</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#awards">Professional Activities</a></li>
                </ul>
            </div>
        </nav>
        <!-- Page Content-->
        <div class="container-fluid p-0">
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                    <h1 class="mb-0">
                        Arslan
                        <span class="text-primary">Siddique</span>
                    </h1>
                    <div class="lead mb-5">
                        Email : <a href="mailto:arslan.siddique@isti.cnr.it">arslan.siddique@isti.cnr.it</a> &emsp; &emsp; &emsp;  &emsp; &emsp; &emsp; &emsp;
                        Skype : hafizas101
 
                    </div>
                    <p class="lead mb-5">I'm from Pakistan and currently working as a Marie Curie Early Stage Researcher for <a href="https://evocation.eu/">EVOCATION ITN</a> in <a href="http://vcg.isti.cnr.it/">Visual Computing Lab</a> which is a part of the prestigious <a href="https://www.isti.cnr.it/it/">ISTI-CNR</a> research institute located in Pisa, Italy. As part of my scholarship, I am also pursuing my PhD studies at <a href="https://www.unipi.it/index.php/english">University of Pisa</a>. I am currently working on projects related to 3D reconstruction and acquisition.</p>
                    <div class="social-icons">
                        <a class="social-icon" href="https://www.linkedin.com/in/arslan-siddique-077251108/"><i class="fab fa-linkedin-in"></i></a>
                        <a class="social-icon" href="https://github.com/hafizas101"><i class="fab fa-github"></i></a>
                        <a class="social-icon" href="https://orcid.org/my-orcid?orcid=0000-0003-0128-8563/"><i class="fab fa-orcid"></i></a>
                        <a class="social-icon" href="https://scholar.google.com/citations?user=RbFGDWsAAAAJ&hl=en"><i class="ai ai-google-scholar "></i></a>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Experience-->
            <section class="resume-section" id="experience">
                <div class="resume-section-content">
                    <h2 class="mb-5">Experience</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Marie Curie Early Stage Researcher</h3>
                            <div class="subheading mb-3"><a href="http://vcg.isti.cnr.it/">Visual Computing Lab</a></div>
                            <p>I am recruited for ESR07 position in <a href="https://evocation.eu/">EVOCATION ITN</a>. My research is focused on 3D reconstruction and point cloud registration. I am currently working on automatic key-frame extraction for real-time video to 3D pipelines.</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">March 2021 - Present</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Research Assistant</h3>
                            <div class="subheading mb-3"><a href="http://vcg.isti.cnr.it/">Istanbul medipol university</a></div>
                            <p>I worked on deep learning based object detection and tracking vehicles in Wide Area Motion Imagery (WAMI). I also co-authored a <a href="https://ieeexplore.ieee.org/abstract/document/9478027">Conference paper.</a></p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">Nov. 2020 - March 2021</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Teaching assistant</h3>
                            <div class="subheading mb-3"><a href="https://innopolis.university/en/">Innopolis University</a></div>
                            <p>I worked as a Teaching Assistant for the course of Sensors, Perception and Actuation with instructor Ilya Afanasyev. My responsibility was to mark all homeworks, quizzes and exams according to instructor's guidelines.</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">Sept. 2020 - Dec. 2020</span></div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Education-->
            <section class="resume-section" id="education">
                <div class="resume-section-content">
                    <h2 class="mb-5">Education</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0"><a href="https://www.unipi.it/index.php/english">University of Pisa, Italy</a></h3>
                            <div class="subheading mb-3">PhD Computer Science</div>
                            <div><b>Thesis Topic : </b>Multi-modal and flexible 3D acquisition </div>
                            <div><b>Thesis Supervisor : </b> <a href="http://vcg.isti.cnr.it/~cignoni/">Paolo Cignoni</a> </div>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">April 2021 - Present </span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0"><a href="https://innopolis.university/en/">Innopolis University, Russia</a></h3>
                            <div class="subheading mb-3">Master's in Computer Science</div>
                            <div><b>Thesis Topic : </b>Trajectory Estimation of vehicles in CCTV data stream </div>
                            <div><b>Thesis Supervisor : </b> Dr. Ilya Afanasyev </div>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">Aug. 2018 - July 2020</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between ">
                        <div class="flex-grow-1">
                            <h3 class="mb-0"><a href="https://www.uet.edu.pk/">University of Engineering and Technology, Pakistan</a></h3>
                            <div class="subheading mb-3">Bachelor's in Electrical Engineering</div>
                            <div><b>Thesis Topic : </b>Design and Implementation of 50kV DC Power Supply </div>
                            <div><b>Thesis Supervisor : </b> Dr. Sidra Farid </div>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">Sept. 2014 - July 2018</span></div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            
            <!-- Projects-->
            <section class="resume-section" id="skills">
                <div class="resume-section-content">
                    <h2 class="mb-5">Selected projects and publications</h2>
                <!-- Portfolio Grid Items-->
                    <p> Click on the image for details of the relevant peoject.</p>
                <div class="row justify-content-center">
                    
                    <!-- Portfolio Item 1-->
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal1">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" src="assets/img/proj_1.png" alt="..." />
                        </div>
                    </div>
                    <!-- Portfolio Item 2--
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal2">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" src="assets/img/proj_2.png" alt="..." />
                        </div>
                    </div>
                    >
                    <!-- Portfolio Item 3-->
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal3">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" src="assets/img/proj_3.png" alt="..." />
                        </div>
                    </div>
                    <!-- Portfolio Item 4-->
                    <div class="col-md-6 col-lg-4 mb-5 mb-lg-0">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal4">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" src="assets/img/proj_4.png" alt="..." />
                        </div>
                    </div>
                    <!-- Portfolio Item 5--
                    <div class="col-md-6 col-lg-4 mb-5 mb-md-0">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal5">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" src="assets/img/proj_5.png" alt="..." />
                        </div>
                    </div>
                    >
                    <!-- Portfolio Item 6--
                    <div class="col-md-6 col-lg-4">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal6">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" src="assets/img/proj_6.jpg" alt="..." />
                        </div>
                    </div>
                    >
                </div>
            </div>
            </section>
            <hr class="m-0" />
            <!-- Interests-->
            <section class="resume-section" id="interests">
                <div class="resume-section-content">
                    <h2 class="mb-5">Skills</h2>
                    <div class="wrapper">
                    <h4 class="mb-1">Technical Skills</h4>
                    <ul>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        Proficient with Python language and programming tools like Jupyter Notebook, Spyder, PyCharm
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        Proficient with Open3d, OpenCV, Keras, Tensorflow, PyTorch
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        Experience with MATLAB, C++ and C.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        Experience with ROS, Gazebo.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        Experience with Ubuntu, Github, OverLeaf.
                    </li>
                </ul>

                    </div>
                    <h4 class="mb-1">Linguistic Skills</h4>
                    <ul>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        Fluent in English. Passed IELTS in January 2020 with Overall 7.5 bands.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        Urdu is my Native language. 
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        Very little Italian and Russian.
                    </li>
                </ul>
                </div>
            </section>
            
            <hr class="m-0" />
            <!-- Awards and Certificates-->
            <section class="resume-section" id="awards">
                <div class="resume-section-content">
                <h2 class="mb-5">Professional Activities</h2>
                <div class="wrapper">
                    <h4 class="mb-1">EVOCATION Training activities</h4>
                    <ul>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        <b>[Nov. 2021]</b> Physical workshop held in <a href="https://www.igd.fraunhofer.de/en/">Fraunhofer IGD</a>
                        <ul>
                            <li> Lectures on 3D printing pipelines and photography </li>
                            <li> Tour of <a href="https://www.stratasys.com//">Stratasys</a> </li>
                            <li> Visit to <a href="https://www.dvwg.de/veranstaltungen/mobilitaetskongress/">Frankfurt FormNext Tradeshow</a> </li>
                        </ul>
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        <b>[Oct. 2021]</b> Virtual Summer School
                        <ul>
                            <li> All ESRs gave their project updates with a 15 minutes live presentation. </li>
                            <li> Lectures from computer graphics researchers and <a href="https://www.laika.com/">LAIKA Studios</a> </li>
                        </ul>
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        <b>[March. 2021]</b> Virtual Workshop in which all ESRs gave their project updates with a 15 minutes live presentation.
                    </li>
                    </ul>
                </div>
                <div class="wrapper">
                    <h4 class="mb-2">Honours and Awards</h4>
                    <ul>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        <b>[Nov. 2021]</b> Awarded with STAG 2021 Graduate school participation <a href="https://drive.google.com/file/d/1uRwCTfWgiK0FLi_pOBLTS_c8GUN_atiq/view?usp=sharing">certificate</a> .
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        <b>[Jan. 2021]</b> Awarded with the prestigious Marie Curie Scholarship for PhD studies. 
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        <b>[June. 2018]</b> Awarded with merit based university scholarship for master's studies at Innopolis University.
                    </li>
                    </ul>
                </div>
                <div class="wrapper">
                    <h4 class="mb-2">Online Courses and certificates</h4>
                    <ul>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        Convolutional Neural Networks [<a href="https://coursera.org/share/8475e6bda3e175728efd2c1de9157124">certificate</a>].
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        Improving Deep Neural Networks : Hyperparameter Tuning, Regularization and Optimization [<a href="https://www.coursera.org/account/accomplishments/records/UMQJX3EW74EA">certificate</a>].
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        Neural Networks and Deep Leaarning [<a href="https://www.coursera.org/account/accomplishments/records/QSNUNPU3N6K4">certificate</a>].
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        ROS for beginners: Basics, Motion and OpenCV [<a href="https://www.udemy.com/certificate/UC-87472Q8L/">certificate</a>].
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                        ROS for Beginners II: Localization, Navigation and SLAM [<a href="https://www.udemy.com/certificate/UC-IY1OM2N7/">certificate</a>].
                    </li>
                    </ul>
                </div>
                </div>
            </section>
        </div>
        
        
        <!-- Portfolio Modals-->
        <!-- Portfolio Modal 1-->
        <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" aria-labelledby="portfolioModal1" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h3 class="portfolio-modal-title text-secondary mb-2">Evaluating deep learning methods for low resolution point cloud registration in outdoor scenarios [<a href="https://diglib.eg.org/handle/10.2312/stag20211489/">pdf</a>] </h3>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-line"></div>

                                    </div>
                                    <!-- Portfolio Modal - Text-->
                                    <p class="mb-4">   Point cloud registration is a fundamental task in 3D reconstruction and environment perception. We explore the performance of modern Deep Learning-based registration techniques, in particular Deep Global Registration (DGR) and Learning Multi-view Registration (LMVR), on an outdoor real world data consisting of thousands of range maps of a building acquired by a Velodyne LIDAR mounted on a drone. We used these pairwise registration methods in a sequential pipeline to obtain an initial rough registration. The output of this pipeline can be further globally refined. This simple registration pipeline allow us to assess if these modern methods are able to deal with this low quality data. Our experiments demonstrated that, despite some design choices adopted to take into account the peculiarities of the data, more work is required to improve the results of the registration.</p>
                                    <button class="btn btn-primary" href="#!" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Portfolio Modal 2--
        <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" aria-labelledby="portfolioModal2" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <h3 class="portfolio-modal-title text-secondary mb-2"> Improved Yolov4 for aerial object detection [<a href="https://ieeexplore.ieee.org/abstract/document/9478027/">pdf</a>] [<a href="https://github.com/sharoseali/modified-yolov4/">code</a>] </h3>
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <p class="mb-4">Drones equipped with cameras are being used for surveillance purposes. These surveillance systems need vision-based object detection of ground objects which look very small because of the altitude of drones. We propose an improved YOLOv4 model targeted for vision-based small object detection. We investigated the performance of state of the art YOLOv4 object detector on the VisDrone dataset. We enhanced the features of small objects by connecting Upsampling layers and concatenating the upsampled features with the original features to obtain more refined and grained features for small objects. Experiments showed that the modified YOLOv4 achieved 2 percent better mAP results as compared to the original YOLOv4 at different image resolutions on the VisDrone dataset while running at the same speed as the original YOLOv4.</p>
                                    <button class="btn btn-primary" href="#!" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        >
        <!-- Portfolio Modal 3-->
        <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" aria-labelledby="portfolioModal3" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h3 class="portfolio-modal-title text-secondary text-uppercase mb-2">Deep learning based trajectory estimation of vehicles in crowded and crossroad scenarios [<a href="https://ieeexplore.ieee.org/document/9347580/">pdf</a>] [<a href="https://github.com/hafizas101/Master-s-thesis.git">code</a>][<a href="https://www.youtube.com/watch?v=HEjMSuSSheA">video</a>]
                                    [<a href="https://www.youtube.com/watch?v=Z8HDD_vWClQ">talk</a>]
                                    
                                    </h3>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image-->
                                    <!-- Portfolio Modal - Text-->
                                    <p class="mb-4">Trajectory estimation of vehicles is an important part of traffic surveillance systems and self driving cars. The difficulty of task lies in variations in light intensity, sizes of objects and real time detection. In the past decade vision based Convolutional Neural Networks have shown some promising results in the area. However, these methods still face problems in crowded and crossroad scenarios when objects are very close together. We propose tracking by detection based trajectory estimation pipeline which consists of two stages: The first stage is the detection and localization of vehicles and the second stage is building associations in bounding boxes and track the associated bounding boxes. We analyze the performance of Mask RCNN benchmark and fYOLOv3 on UA DETRAC dataset which is a large scale real life traffic dataset. We evaluate certain metrics like inference time, Intersection over union (IoU), Precision Recall (PR) curve and mean Average Precision (mAP). Experiments show that Mask RCNN outperforms YOLOv3. After that, we analyze the performance of centroid tracker and SORT tracker. Experiments show that SORT tracker gives us smoother trajectory as compared to noisy trajectory obtained from centroid tracker. However, SORT tracker based trajectory gives 4 pixels more Euclidean distance loss than Centroid tracker based trajectory.</p>
                                    <button class="btn btn-primary" href="#!" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Portfolio Modal 4-->
        <div class="portfolio-modal modal fade" id="portfolioModal4" tabindex="-1" aria-labelledby="portfolioModal4" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <h3 class="portfolio-modal-title text-secondary text-uppercase mb-2">ROS-based integration of smart space and mobile robot as internet of robotic things [<a href="https://ieeexplore.ieee.org/document/8981532/">pdf</a>] [<a href="https://github.com/hafizas101/SmartEnvironment.git">code</a>]</h3>
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <p class="mb-4">The rapid developments in the field of Artificial Intelligence are bringing enhancements in the area of intelligent transport systems by overcoming the challenges of safety concerns. Traffic surveillance systems based on CCTV cameras can help us to achieve safe and sustainable transport systems. Trajectory estimation of vehicles is an important part of traffic surveillance systems and self-driving cars. The task is challenging due to the variations in illumination intensities, object sizes and real-time detection. We propose tracking by detection based trajectory estimation pipeline which consists of two stages: The first stage is the detection and localization of vehicles and the second stage is building associations in bounding boxes and track the associated bounding boxes. We analyze the performance of the Mask RCNN benchmark and YOLOv3 on the UA-DETRAC dataset and evaluate certain metrics like Intersection over Union, Precision-Recall curve, and Mean Average Precision. Experiments show that Mask RCNN Benchmark outperforms YOLOv3 in terms of accuracy. SORT tracker is applied on detected bounding boxes to estimate trajectories. The tracker is evaluated using mean absolute error. We demonstrate that the developed technique works successfully in crowded and crossroad scenarios.</p>
                                    <button class="btn btn-primary" href="#!" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Portfolio Modal 5--
        <div class="portfolio-modal modal fade" id="portfolioModal5" tabindex="-1" aria-labelledby="portfolioModal5" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <h3 class="portfolio-modal-title text-secondary text-uppercase mb-2">Moving vehicle detection in wide area motion imagery (WAMI) [<a href="https://github.com/hafizas101/centertrack_wami.git">code</a>] </h3>
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-line"></div>
                                    </div>

                                    <p class="mb-4">This project aims to detect and track very small moving vehicles in high altitude wide area motion images. CenterTrack algorithm was trained on moving vehicles in WPAFB 2009 dataset and results were compared with state of the art. The trained algorithm was found 8 times faster than the existing algorithms while achieving similar accuracy.</p>
                                    <button class="btn btn-primary" href="#!" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        >
        <!-- Portfolio Modal 6--
        <div class="portfolio-modal modal fade" id="portfolioModal6" tabindex="-1" aria-labelledby="portfolioModal6" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <h3 class="portfolio-modal-title text-secondary text-uppercase mb-0">Real-time Multi-object tracking for drone surveillance systems [<a href="https://github.com/hafizas101/visdrone-centertrack.git">code</a>] [<a href="https://www.youtube.com/watch?v=q1-l-brHvgU&ab_channel=ArslanSiddique">video</a>]</h3>
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <p class="mb-4">The rapid developments in the area of Artificial Intelligence and Computer Vision are bringing enhancements in the field of drone surveillance and delivery systems. Object detection and tracking is a very important part of these aerial surveillance systems. The task is challenging due to variations in drone heights, object sizes, illumination etc. We use simultaneous detection and tracking based algorithm namely CenterTrack to achieve real time and accurate results on VisDrone dataset. We trained the CenterTrack algorithm on VisDrone training dataset in several experiment settings and report the results on test-dev portion. We calculated mean Average Precision (mAP)  results of our trained models and compared them with state of the art results on MOT leaderboard. Our model achieved 8.04\% mAP at a speed of 14 FPS for an input images of size 1360 X 765.</p>
                                    <button class="btn btn-primary" href="#!" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        >
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
